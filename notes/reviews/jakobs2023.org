Commentaires globaux :
- féliciter pour reprendre le code et publier les résultats de manière honnête (important !)
- Remarque globale : difficile parfois de voir l'apport par rapport au modèle existant
- on reste sur notre faim pour la précision
- pourquoi tester sur du GPU au final ? On "sait" qu'on va être limité par la mémoire

Contexte:
- version 6 déjà parallélisée : en C (CPU ?): speed 216, avec opeacc (67) et CUDA (4-5)
- version 7 : la grèle est une catégorie supplémentaire (et non pas simplement de la "neige roulée" -> pas clair, voir Bae 2018 [[file:~/research/biblio.org::*Development of a Single-Moment Cloud Microphysics Scheme with Prognostic Hail for the Weather Research and Forecasting (WRF) Model][Bae 2018]]] )
#+begin_quote
the WSM6 model is extended to a four-ice microphysics scheme by considering the
hydrometeor hail as an additional category rather than solely relying on graupel.
#+end_quote
* Intro
- Contexte: https://link.springer.com/article/10.1007/s13143-018-0066-3 Ajout de la grêle dans le modèle
- Grille : régulière ? À préciser
- Étendue du modèle (national probablement)
* 3
Argument sur le choix du C au lieu de Fortran n'est pas très clair
#+begin_quote
for this work the Fortran version is reimplemented in C++ using CUDA due
to the extensive usage of object orientation for the creation of GPU tasks, which only
can be represented insufficiently in Fortran based approaches like CUDA-Fortran.
#+end_quote
** Parallélisation :
- comment sont réparties les tâches de calcul (1 colonne = 1 tache a priori) ? Simple pile ou algorithme plus compliqué ?
#+begin_quote
Each column can be simulated in parallel allowing for a simultane-
ous calculation along the horizontal mesh points following the longitude and latitude
coordinates
#+end_quote
Cette phrase peut être supprimée car redondante

- Question: charge de calcul équilibrée horizontalement ? Et verticalement ? Il serait intéressant de voir la charge de calcul au cours du temps

Figure 2 : type "Daten" -> data, type "direkt" -> direct
* 4
- WPS = ?
CONUS = ?
MM5 ?

- Erreur : single float donc en-dessous du seuil ???

Précision:
- Comparaison entre Fortran et GPU: ok pour la non-régression mais par rapport aux observations ?? Le modèle a échoué à prédire (à vérifier) mais la version parallèle semble mieux prédite. Due à la meilleure précision ou artefact de la parallilésation ?
- testé sur le modèle 2D de Bae et al 2018 ?
* 5 Résultats
- Choix de la résolution : Correspond aux simulations réelles ? (400 points en latitue ~ 2km pour l'allemagne)
- 5.3: comment est calculé le maximum speedup (mesure/calcul ? détailler dans les 2 cas)?
- Fortran : déjà parallélisé donc ?
- 4 threads = pas plus ?
- performance inférieure du C
- 5.3 : manque majuscule à "thus"
- Pas clair : tâche dans quel sens ? Au lieu d'avoir une grosse boucle, on a des appels de fonctions dedans ? Ou bien sur des threads différentes ?
  #+begin_quote
In the C implementation, single calculation steps are described isolated from each other in separate tasks
  #+end_quote
- donner les compilateur fortran + C (et la version), ainsi que les flags

5.4: maintenant la version "hôte"  est en Fortran et non en C ??? À préciser (semble être le cas avec la conclusion)
#+begin_quote
The heterogeneous approach utilizes the CPU
through the Fortran implementation where one of the four threads starts the master
thread for the GPU implementation.
#+end_quote
- De manière générale, chiffres sur un seul run ? À préciser
- figure 11: low-pass filter = filtre sur variant de forte amplitude
- les auteurs ont-il essayé de faire une moyenne "glissante" en modifiant la charge de calcul par rapport à un temps moyens, par exemple sur 100 itérations pour lisser ?
* Conclusion
- futur ? sur quelle architecture envisagent-ils de tourner en production ?
